{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mauri\\anaconda3\\envs\\AI\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth\" to C:\\Users\\mauri/.cache\\torch\\hub\\checkpoints\\efficientnet_b4_rwightman-23ab8bcd.pth\n",
      "100%|██████████| 74.5M/74.5M [00:09<00:00, 8.11MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.efficientnet_b4(models.EfficientNet_B4_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_emb(model, img):\n",
    "    x = model.features(img)\n",
    "    x = model.avgpool(x)\n",
    "    return torch.flatten(x, 1).squeeze(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<class 'torchvision.transforms._presets.ImageClassification'>, crop_size=380, resize_size=384, interpolation=<InterpolationMode.BICUBIC: 'bicubic'>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.EfficientNet_B4_Weights.DEFAULT.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:20<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir_str = \"images\"\n",
    "directory = os.fsencode(dir_str)\n",
    "embeddings = list()\n",
    "\n",
    "for file in tqdm(os.listdir(directory)):\n",
    "    filename = os.fsdecode(file)\n",
    "    img = transforms.Compose([\n",
    "        transforms.Resize((384, 384), Image.BICUBIC),\n",
    "        transforms.CenterCrop(380),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])(Image.open('/'.join((dir_str,filename)))).unsqueeze(0)\n",
    "    # print(img.shape) # torch.Size([1, 3, 384, 384])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = get_emb(model, img)\n",
    "\n",
    "    embeddings.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1792"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 1792)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.array(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = embeddings[35]\n",
    "\n",
    "cos_sims = list()\n",
    "\n",
    "for idx, img in enumerate(embeddings):\n",
    "    cos_sim = np.dot(base, img)/(np.linalg.norm(base)*np.linalg.norm(img))\n",
    "    cos_sims.append((cos_sim, idx))\n",
    "\n",
    "cos_sims.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 35),\n",
       " (0.8868286420362609, 6),\n",
       " (0.8264174662778809, 11),\n",
       " (0.7878606883208698, 33),\n",
       " (0.7700424473057442, 19),\n",
       " (0.769071105898622, 12),\n",
       " (0.7633499864789764, 1),\n",
       " (0.7607359268288509, 4),\n",
       " (0.743370488381418, 10),\n",
       " (0.7430450052114606, 32),\n",
       " (0.7284250071864187, 13),\n",
       " (0.7159573363484643, 31),\n",
       " (0.71497390019577, 21),\n",
       " (0.6817514279012727, 38),\n",
       " (0.6420223216477583, 34),\n",
       " (0.628414056483935, 3),\n",
       " (0.6103807483675272, 23),\n",
       " (0.6095492616837259, 17),\n",
       " (0.6011928739028061, 39),\n",
       " (0.5869402824824432, 22),\n",
       " (0.5779961887313033, 16),\n",
       " (0.5556637374567358, 8),\n",
       " (0.5444095932209682, 7),\n",
       " (0.528101382790358, 15),\n",
       " (0.5094797516735364, 25),\n",
       " (0.5043835469240293, 0),\n",
       " (0.5033128592476008, 30),\n",
       " (0.5015538902980392, 37),\n",
       " (0.49744471357147474, 20),\n",
       " (0.4695109853765545, 26),\n",
       " (0.43682679176403605, 5),\n",
       " (0.4311139129250266, 2),\n",
       " (0.42934942979144747, 29),\n",
       " (0.4168917021425288, 27),\n",
       " (0.4135452006091975, 14),\n",
       " (0.398632075550831, 24),\n",
       " (0.39284851171931223, 9),\n",
       " (0.38620548978237407, 40),\n",
       " (0.3839948027331606, 28),\n",
       " (0.3136688134498109, 36),\n",
       " (0.27890092549868994, 18)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 img_0_0.jpg\n",
      "1 img_0_1.jpg\n",
      "2 img_0_2.jpg\n",
      "3 img_10_0.jpg\n",
      "4 img_10_1.jpg\n",
      "5 img_10_2.jpg\n",
      "6 img_11_0.jpg\n",
      "7 img_11_1.jpg\n",
      "8 img_11_2.jpg\n",
      "9 img_12_0.jpg\n",
      "10 img_12_1.jpg\n",
      "11 img_12_2.jpg\n",
      "12 img_13_0.jpg\n",
      "13 img_13_1.jpg\n",
      "14 img_13_2.jpg\n",
      "15 img_14_0.jpg\n",
      "16 img_1_0.jpg\n",
      "17 img_1_1.jpg\n",
      "18 img_1_2.jpg\n",
      "19 img_2_0.jpg\n",
      "20 img_2_1.jpg\n",
      "21 img_2_2.jpg\n",
      "22 img_3_0.jpg\n",
      "23 img_3_1.jpg\n",
      "24 img_3_2.jpg\n",
      "25 img_4_0.jpg\n",
      "26 img_4_1.jpg\n",
      "27 img_4_2.jpg\n",
      "28 img_5_0.jpg\n",
      "29 img_5_1.jpg\n",
      "30 img_5_2.jpg\n",
      "31 img_6_0.jpg\n",
      "32 img_6_1.jpg\n",
      "33 img_6_2.jpg\n",
      "34 img_7_0.jpg\n",
      "35 img_7_1.jpg\n",
      "36 img_8_0.jpg\n",
      "37 img_8_1.jpg\n",
      "38 img_8_2.jpg\n",
      "39 img_9_0.jpg\n",
      "40 img_9_1.jpg\n"
     ]
    }
   ],
   "source": [
    "for idx, file in enumerate(os.listdir(directory)):\n",
    "    filename = os.fsdecode(file)\n",
    "    print(idx, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
